	!pip install pandas librosa matplotlib scikit-learn
!pip install numpy

import os
import numpy as np
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

audio_dir = r'C:\Users\Tejash\OneDrive\Desktop\Sound' # <-- your folder

def extract_features(file_path, sr=22050, n_mfcc=13):
    y, _ = librosa.load(file_path, sr=sr)
    features = {}
    features['zcr'] = np.mean(librosa.feature.zero_crossing_rate(y))
    features['rms'] = np.mean(librosa.feature.rms(y=y))
    features['centroid'] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    features['bw'] = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))
    features['rolloff'] = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))
    features['contrast'] = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))
    features['tonnetz'] = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr))
    features['chroma'] = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    for i in range(n_mfcc):
        features[f'mfcc_{i+1}'] = np.mean(mfccs[i])
    features['duration'] = librosa.get_duration(y=y, sr=sr)
    return features

data = []
for root, dirs, files in os.walk(audio_dir):
    for fname in files:
        if fname.lower().endswith(('.wav', '.ogg')):
            fpath = os.path.join(root, fname)
            feats = extract_features(fpath)
            # Change next line only if your label is not the parent folder name
            feats['label'] = os.path.basename(root) # <-- you may need to change label extraction if not grouped
            data.append(feats)

df = pd.DataFrame(data)

print(df.head()) # Check for sanity

X = df.drop('label', axis=1).values
y = df['label'].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Visualization for a single file
sample_file = r'C:\Users\Tejash\OneDrive\Desktop\Sound\Recording2.wav' # <-- update to your sample audio file path
y_s, sr = librosa.load(sample_file, sr=None)
plt.figure(figsize=(12,4))
librosa.display.waveshow(y_s, sr=sr)
plt.title('Waveform')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,4))
D = librosa.amplitude_to_db(np.abs(librosa.stft(y_s)), ref=np.max)
librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')
plt.colorbar()
plt.title('Spectrogram (dB)')
plt.tight_layout()
plt.show()

mfccs = librosa.feature.mfcc(y=y_s, sr=sr, n_mfcc=13)
plt.figure(figsize=(10,4))
librosa.display.specshow(mfccs, x_axis='time', sr=sr)
plt.colorbar()
plt.title('MFCC')
plt.tight_layout()
plt.show()
